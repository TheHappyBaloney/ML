{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3173719,"sourceType":"datasetVersion","datasetId":952827}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Package Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\n\nprint(\"Import Successful\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T03:35:59.571637Z","iopub.execute_input":"2024-04-29T03:35:59.572348Z","iopub.status.idle":"2024-04-29T03:35:59.580020Z","shell.execute_reply.started":"2024-04-29T03:35:59.572315Z","shell.execute_reply":"2024-04-29T03:35:59.578581Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Import Successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training Dataset Pre-processing","metadata":{}},{"cell_type":"code","source":"# Training Data Pre-processing\n\ntraining_set = tf.keras.utils.image_dataset_from_directory(\n    '/kaggle/input/fruit-and-vegetable-image-recognition/train',\n    labels = 'inferred' ,\n    label_mode = 'categorical' ,\n    class_names = None ,\n    color_mode = 'rgb' ,\n    batch_size = 32 ,\n    image_size = ( 64 , 64 ) ,\n    shuffle = True ,\n    seed = None ,\n    validation_split = None ,\n    subset = None ,\n    interpolation = 'bilinear' ,\n    follow_links = False ,\n    crop_to_aspect_ratio = False\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T03:42:21.134111Z","iopub.execute_input":"2024-04-29T03:42:21.134542Z","iopub.status.idle":"2024-04-29T03:42:21.866611Z","shell.execute_reply.started":"2024-04-29T03:42:21.134503Z","shell.execute_reply":"2024-04-29T03:42:21.865436Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 3115 files belonging to 36 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Validation Dataset Pre-processing","metadata":{}},{"cell_type":"code","source":"# Validation Data Pre-processing\n\nvalidation_set = tf.keras.utils.image_dataset_from_directory(\n    '/kaggle/input/fruit-and-vegetable-image-recognition/validation',\n    labels = 'inferred' ,\n    label_mode = 'categorical' ,\n    class_names = None ,\n    color_mode = 'rgb' ,\n    batch_size = 32 ,\n    image_size = ( 64 , 64 ) ,\n    shuffle = True ,\n    seed = None ,\n    validation_split = None ,\n    subset = None ,\n    interpolation = 'bilinear' ,\n    follow_links = False ,\n    crop_to_aspect_ratio = False\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T03:44:09.455099Z","iopub.execute_input":"2024-04-29T03:44:09.455556Z","iopub.status.idle":"2024-04-29T03:44:09.569093Z","shell.execute_reply.started":"2024-04-29T03:44:09.455525Z","shell.execute_reply":"2024-04-29T03:44:09.567830Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 351 files belonging to 36 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Building Model ","metadata":{}},{"cell_type":"code","source":"# Defining the model architecture\nmodel = Sequential([\n    Flatten(input_shape=(64, 64, 3)),  \n    Dense(128, activation='relu'),     \n    Dense(64, activation='relu'),      \n    Dense(36, activation='softmax')    \n])\n\n# Compiling the model\nmodel.compile(\n    optimizer='adam',                 \n    loss='categorical_crossentropy',  \n    metrics=['accuracy']              \n)\n\n# Displaying the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T03:49:02.861041Z","iopub.execute_input":"2024-04-29T03:49:02.861490Z","iopub.status.idle":"2024-04-29T03:49:02.932396Z","shell.execute_reply.started":"2024-04-29T03:49:02.861457Z","shell.execute_reply":"2024-04-29T03:49:02.931139Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,572,992\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │         \u001b[38;5;34m2,340\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,572,992</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,340</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,583,588\u001b[0m (6.04 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,583,588</span> (6.04 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,583,588\u001b[0m (6.04 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,583,588</span> (6.04 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}